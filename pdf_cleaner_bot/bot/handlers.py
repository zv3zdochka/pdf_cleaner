from __future__ import annotations

import asyncio
import logging
import re
import shutil
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

import fitz  # PyMuPDF
from aiogram import Bot
from aiogram.exceptions import TelegramBadRequest
from aiogram.types import (
    CallbackQuery,
    FSInputFile,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    Message,
)

from pdf_cleaner_bot.storage.manager import StorageManager

# user_id -> request_id (–æ–∂–∏–¥–∞–Ω–∏–µ –≤–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü)
_PENDING_PAGES_INPUT: Dict[int, str] = {}


def _human_bytes(n: int) -> str:
    units = ["B", "KB", "MB", "GB", "TB"]
    v = float(max(0, n))
    i = 0
    while v >= 1024 and i < len(units) - 1:
        v /= 1024
        i += 1
    if i == 0:
        return f"{int(v)} {units[i]}"
    return f"{v:.2f} {units[i]}"


def _kb_for_request(request_id: str) -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        inline_keyboard=[
            [InlineKeyboardButton(text="‚úÖ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å", callback_data=f"pdfc:proc:{request_id}")],
            [InlineKeyboardButton(text="üóë –ó–∞–¥–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è", callback_data=f"pdfc:pages:{request_id}")],
        ]
    )


def _parse_pages_spec(spec: str, max_page: int) -> List[int]:
    """
    "1, 2, 4-6" -> [1,2,4,5,6] (1-based)
    —Å—Ç—Ä–æ–≥–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: –ª—é–±–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤–Ω–µ 1..max_page -> –æ—à–∏–±–∫–∞
    """
    s = (spec or "").strip()
    if not s or s in {"0", "–Ω–µ—Ç", "none", "no"}:
        return []

    if "," not in s and " " in s:
        s = re.sub(r"\s+", ",", s)

    out: Set[int] = set()
    parts = [p.strip() for p in s.split(",") if p.strip()]
    if not parts:
        return []

    for p in parts:
        if "-" in p:
            a_str, b_str = [x.strip() for x in p.split("-", 1)]
            if not a_str or not b_str:
                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: '{p}'. –ü—Ä–∏–º–µ—Ä: 4-6")
            if not a_str.isdigit() or not b_str.isdigit():
                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: '{p}'. –ü—Ä–∏–º–µ—Ä: 4-6")
            a = int(a_str)
            b = int(b_str)
            if a <= 0 or b <= 0:
                raise ValueError("–ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å >= 1")
            if a > b:
                a, b = b, a
            for x in range(a, b + 1):
                out.add(x)
        else:
            if not p.isdigit():
                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã: '{p}'")
            x = int(p)
            if x <= 0:
                raise ValueError("–ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å >= 1")
            out.add(x)

    bad = [x for x in out if x > max_page]
    if bad:
        raise ValueError(f"–ï—Å—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 1..{max_page}: {sorted(bad)}")

    res = sorted(out)
    if len(res) == max_page:
        raise ValueError("–ù–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ü–µ–ª–∏–∫–æ–º (–¥–æ–∫—É–º–µ–Ω—Ç —Å—Ç–∞–Ω–µ—Ç –ø—É—Å—Ç—ã–º).")
    return res


def _pdf_page_count(pdf_path: Path) -> int:
    d = fitz.open(pdf_path)
    n = d.page_count
    d.close()
    return n


def _remove_pages_copy(
    src_pdf: Path,
    dst_pdf: Path,
    pages_to_delete_1based: List[int],
) -> Tuple[int, int]:
    """
    –°–æ–∑–¥–∞—ë—Ç –∫–æ–ø–∏—é dst_pdf –∏–∑ src_pdf, —É–¥–∞–ª—è—è —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (1-based).
    –ò—Å—Ö–æ–¥–Ω–∏–∫ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (old_pages, new_pages).
    """
    src = fitz.open(src_pdf)
    old_n = src.page_count

    if not pages_to_delete_1based:
        # –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º —Ü–µ–ª–∏–∫–æ–º
        dst = fitz.open()
        dst.insert_pdf(src)
        dst.save(dst_pdf, garbage=3, deflate=True, clean=True)
        dst.close()
        src.close()
        return old_n, old_n

    del_set = set(pages_to_delete_1based)
    keep = [i for i in range(old_n) if (i + 1) not in del_set]
    if not keep:
        src.close()
        raise ValueError("–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç —Å—Ç–∞–ª –±—ã –ø—É—Å—Ç—ã–º.")

    dst = fitz.open()
    for i in keep:
        dst.insert_pdf(src, from_page=i, to_page=i)

    tmp = dst_pdf.with_suffix(".tmp.pdf")
    dst.save(tmp, garbage=3, deflate=True, clean=True)
    dst.close()
    src.close()
    tmp.replace(dst_pdf)

    new_n = _pdf_page_count(dst_pdf)
    return old_n, new_n


def _split_pdf_to_parts_under_limit(
    pdf_path: Path,
    *,
    max_bytes: int,
    tmp_root: Path,
    base_filename_stem: str,
    logger: logging.LoggerAdapter,
) -> List[Path]:
    tmp_root.mkdir(parents=True, exist_ok=True)
    src = fitz.open(pdf_path)
    n = src.page_count

    # –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
    limit = max(1, int(max_bytes) - 256 * 1024)

    parts: List[Path] = []
    cur_pages: List[int] = []

    def save_pages(pages: List[int], part_idx: int) -> Path:
        out = fitz.open()
        for pi in pages:
            out.insert_pdf(src, from_page=pi, to_page=pi)
        out_path = tmp_root / f"{base_filename_stem}_part{part_idx:02d}.pdf"
        out.save(out_path, garbage=3, deflate=True, clean=True)
        out.close()
        return out_path

    part_idx = 1
    i = 0
    while i < n:
        trial = cur_pages + [i]
        trial_path = save_pages(trial, part_idx)
        sz = trial_path.stat().st_size

        if sz <= limit:
            cur_pages = trial
            i += 1
            continue

        trial_path.unlink(missing_ok=True)

        if not cur_pages:
            src.close()
            raise ValueError("–û–¥–Ω–∞ –∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –∏ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç Telegram.")

        final_path = save_pages(cur_pages, part_idx)
        final_sz = final_path.stat().st_size
        logger.info(
            "Split part %s: pages=%s..%s size=%s",
            part_idx,
            cur_pages[0] + 1,
            cur_pages[-1] + 1,
            final_sz,
        )
        parts.append(final_path)
        part_idx += 1
        cur_pages = []

    if cur_pages:
        final_path = save_pages(cur_pages, part_idx)
        final_sz = final_path.stat().st_size
        logger.info(
            "Split part %s: pages=%s..%s size=%s",
            part_idx,
            cur_pages[0] + 1,
            cur_pages[-1] + 1,
            final_sz,
        )
        parts.append(final_path)

    src.close()
    return parts


async def cmd_start(message: Message) -> None:
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –ü—Ä–∏—à–ª–∏ PDF.\n\n"
        "–Ø —Å–æ—Ö—Ä–∞–Ω—é –µ–≥–æ –∏ –ø–æ–∫–∞–∂—É –∫–∞—Ä—Ç–æ—á–∫—É (–∏–º—è/—Ä–∞–∑–º–µ—Ä/—Å—Ç—Ä–∞–Ω–∏—Ü—ã/–≤—Ä–µ–º—è) + –∫–Ω–æ–ø–∫–∏:\n"
        "‚Äî –û–±—Ä–∞–±–æ—Ç–∞—Ç—å\n"
        "‚Äî –ó–∞–¥–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è\n\n"
        "–§–∞–π–ª—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å."
    )


async def handle_document(
    message: Message,
    bot: Bot,
    *,
    telegram_max_file_size: int,
    internal_max_file_size: int,
    storage: StorageManager,
) -> None:
    """
    –ü—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ PDF:
      - —Å–æ—Ö—Ä–∞–Ω—è–µ–º input_original.pdf
      - –ø–∏—à–µ–º meta
      - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫—É + –∫–Ω–æ–ø–∫–∏
    """
    document = message.document
    if not document:
        return

    user_id = message.from_user.id if message.from_user else 0
    original_filename = document.file_name or "document.pdf"
    file_size = document.file_size or 0

    log = logging.getLogger("pdf_cleaner.bot.handlers")

    if file_size > telegram_max_file_size:
        await message.reply(
            "–≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è Telegram-–±–æ—Ç–∞ (‚âà50 –ú–ë). "
            "–°–æ–∂–º–∏—Ç–µ PDF –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    if file_size > internal_max_file_size:
        await message.reply("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ª–∏–º–∏—Ç 1 –ì–ë).")
        return

    if not original_filename.lower().endswith(".pdf"):
        await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ PDF-—Ñ–∞–π–ª.")
        return

    # –∫–≤–æ—Ç–∞ –¥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø—Ä–∏–º–µ—Ä–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ–º +file_size)
    if storage.would_exceed_quota(file_size):
        await message.reply(
            "–•—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ (–ª–∏–º–∏—Ç 30 –ì–ë). "
            "–£–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    request_id = uuid.uuid4().hex
    rd = storage.request_dir(user_id, request_id)
    rd.mkdir(parents=True, exist_ok=True)

    input_original = rd / "input_original.pdf"
    input_trimmed = rd / "input_trimmed.pdf"
    cleaned = rd / "cleaned.pdf"
    cleaned_small = rd / "cleaned_small.pdf"

    meta: Dict[str, Any] = {
        "request_id": request_id,
        "user_id": user_id,
        "original_filename": original_filename,
        "status": "received",
        "created_at": int(time.time()),
        "updated_at": int(time.time()),
        "pages_total_original": None,
        "pages_total_effective": None,
        "pages_to_delete": [],
        "input": {
            "original": {"path": str(input_original.relative_to(storage.cfg.root_dir)), "size_bytes": file_size},
            "trimmed": None,
        },
        "output": {},
        "errors": [],
    }
    storage.write_meta(user_id, request_id, meta)

    adapter = logging.LoggerAdapter(log, {"request_id": request_id})
    adapter.info("Incoming file: name=%s size=%s bytes", original_filename, file_size)

    # download
    try:
        tg_file = await bot.get_file(document.file_id)
    except TelegramBadRequest as e:
        adapter.exception("TelegramBadRequest on get_file: %s", e)
        meta["status"] = "failed_get_file"
        meta["updated_at"] = int(time.time())
        meta["errors"].append({"stage": "get_file", "error": str(e)})
        storage.write_meta(user_id, request_id, meta)
        await message.reply("Telegram –æ—Ç–∫–∞–∑–∞–ª—Å—è –æ—Ç–¥–∞–≤–∞—Ç—å —Ñ–∞–π–ª (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –æ–Ω —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π).")
        return

    await bot.download_file(tg_file.file_path, destination=input_original)

    # page count
    try:
        pages_total = _pdf_page_count(input_original)
    except Exception as e:
        adapter.exception("Failed to open PDF for page count: %s", e)
        meta["status"] = "failed_open_pdf"
        meta["updated_at"] = int(time.time())
        meta["errors"].append({"stage": "open_pdf", "error": str(e)})
        storage.write_meta(user_id, request_id, meta)
        await message.reply("–ù–µ —Å–º–æ–≥ –æ—Ç–∫—Ä—ã—Ç—å PDF (–≤–æ–∑–º–æ–∂–Ω–æ —Ñ–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥—ë–Ω).")
        return

    # update meta
    meta["status"] = "ready"
    meta["updated_at"] = int(time.time())
    meta["pages_total_original"] = pages_total
    meta["pages_total_effective"] = pages_total
    meta["input"]["original"]["size_bytes"] = input_original.stat().st_size if input_original.exists() else 0
    meta["input"]["trimmed"] = None
    meta["output"] = {}
    storage.write_meta(user_id, request_id, meta)

    # show card
    sent_dt = message.date
    sent_str = sent_dt.strftime("%Y-%m-%d %H:%M:%S") if sent_dt else datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
    size_str = _human_bytes(int(meta["input"]["original"]["size_bytes"]))

    text = (
        "–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω.\n\n"
        f"–ò–º—è: {original_filename}\n"
        f"–†–∞–∑–º–µ—Ä: {size_str}\n"
        f"–°—Ç—Ä–∞–Ω–∏—Ü: {pages_total}\n"
        f"–í—Ä–µ–º—è: {sent_str} (UTC)\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
    )
    await message.reply(text, reply_markup=_kb_for_request(request_id))


async def handle_pages_text(
    message: Message,
    *,
    storage: StorageManager,
) -> None:
    """
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–æ–¥–∏—Ç —Å—Ç—Ä–æ–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü.
    –ú—ã —Å–æ–∑–¥–∞—ë–º input_trimmed.pdf –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–æ–ø–∏—é.
    """
    user_id = message.from_user.id if message.from_user else 0
    if user_id not in _PENDING_PAGES_INPUT:
        return

    request_id = _PENDING_PAGES_INPUT[user_id]
    rd = storage.request_dir(user_id, request_id)
    meta = storage.read_meta(user_id, request_id) or {}
    input_original = rd / "input_original.pdf"
    input_trimmed = rd / "input_trimmed.pdf"

    if not input_original.exists():
        _PENDING_PAGES_INPUT.pop(user_id, None)
        await message.reply("–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—Ç–ø—Ä–∞–≤—å—Ç–µ PDF –∑–∞–Ω–æ–≤–æ.")
        return

    pages_total = int(meta.get("pages_total_original") or 0)
    if pages_total <= 0:
        try:
            pages_total = _pdf_page_count(input_original)
        except Exception:
            _PENDING_PAGES_INPUT.pop(user_id, None)
            await message.reply("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ.")
            return

    spec = (message.text or "").strip()

    try:
        pages = _parse_pages_spec(spec, pages_total)
    except ValueError as e:
        await message.reply(
            f"–ù–µ –ø–æ–Ω—è–ª —Ñ–æ—Ä–º–∞—Ç.\n–û—à–∏–±–∫–∞: {e}\n\n"
            "–í–≤–µ–¥–∏—Ç–µ —Ç–∞–∫: 1,2,4-6\n"
            f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü: 1..{pages_total}\n"
            "–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ 0, —á—Ç–æ–±—ã –æ—á–∏—Å—Ç–∏—Ç—å —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª–µ–Ω–∏—è."
        )
        return

    log = logging.getLogger("pdf_cleaner.bot.handlers")
    adapter = logging.LoggerAdapter(log, {"request_id": request_id})

    # –ï—Å–ª–∏ –æ—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ (pages == []): —É–¥–∞–ª—è–µ–º trimmed-—Ñ–∞–π–ª (–µ—Å–ª–∏ –±—ã–ª) –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º output
    if not pages:
        input_trimmed.unlink(missing_ok=True)

        # —Ç–∞–∫–∂–µ —É–¥–∞–ª–∏–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ø—É—Ç–∞–Ω–∏—Ü—ã
        (rd / "cleaned.pdf").unlink(missing_ok=True)
        (rd / "cleaned_small.pdf").unlink(missing_ok=True)

        meta["pages_to_delete"] = []
        meta["input"]["trimmed"] = None
        meta["pages_total_effective"] = int(meta.get("pages_total_original") or pages_total)
        meta["output"] = {}
        meta["status"] = "ready"
        meta["updated_at"] = int(time.time())
        storage.write_meta(user_id, request_id, meta)

        _PENDING_PAGES_INPUT.pop(user_id, None)
        await message.reply("–û–∫. –°–ø–∏—Å–æ–∫ —É–¥–∞–ª–µ–Ω–∏—è –æ—á–∏—â–µ–Ω.\n\n–ù–∞–∂–º–∏—Ç–µ ¬´–û–±—Ä–∞–±–æ—Ç–∞—Ç—å¬ª.", reply_markup=_kb_for_request(request_id))
        return

    # –û—Ü–µ–Ω–∫–∞ –ø–æ –∫–≤–æ—Ç–µ: —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ø–∏–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å ~—Ä–∞–∑–º–µ—Ä–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ)
    orig_size = input_original.stat().st_size if input_original.exists() else 0
    if storage.would_exceed_quota(orig_size):
        await message.reply(
            "–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –º–µ—Å—Ç–∞, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—É—é –∫–æ–ø–∏—é (–ª–∏–º–∏—Ç 30 –ì–ë). "
            "–£–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return

    # –ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–∏–Ω–∞—á–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)
    (rd / "cleaned.pdf").unlink(missing_ok=True)
    (rd / "cleaned_small.pdf").unlink(missing_ok=True)

    # –°–æ–∑–¥–∞—ë–º trimmed-–∫–æ–ø–∏—é
    try:
        old_n, new_n = _remove_pages_copy(input_original, input_trimmed, pages)
    except Exception as e:
        adapter.exception("Failed to create trimmed copy: %s", e)
        await message.reply(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—É—é –∫–æ–ø–∏—é: {e}")
        return

    meta["pages_to_delete"] = pages
    meta["input"]["trimmed"] = {
        "path": str(input_trimmed.relative_to(storage.cfg.root_dir)),
        "size_bytes": input_trimmed.stat().st_size if input_trimmed.exists() else 0,
        "pages_deleted": pages,
        "pages_before": old_n,
        "pages_after": new_n,
    }
    meta["pages_total_effective"] = new_n
    meta["output"] = {}
    meta["status"] = "ready"
    meta["updated_at"] = int(time.time())
    storage.write_meta(user_id, request_id, meta)

    _PENDING_PAGES_INPUT.pop(user_id, None)

    await message.reply(
        f"–û–∫. –°–æ—Ö—Ä–∞–Ω–∏–ª –æ–±—Ä–µ–∑–∞–Ω–Ω—É—é –∫–æ–ø–∏—é (—Å—Ç—Ä–∞–Ω–∏—Ü –±—ã–ª–æ {old_n}, —Å—Ç–∞–ª–æ {new_n}).\n"
        f"–£–¥–∞–ª–µ–Ω—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {pages}\n\n"
        "–ù–∞–∂–º–∏—Ç–µ ¬´–û–±—Ä–∞–±–æ—Ç–∞—Ç—å¬ª.",
        reply_markup=_kb_for_request(request_id),
    )


async def handle_callback(
    query: CallbackQuery,
    *,
    processor,
    shrink_pdf,
    process_lock: asyncio.Lock,
    telegram_max_file_size: int,
    internal_max_file_size: int,  # –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    storage: StorageManager,
) -> None:
    await query.answer()

    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏ (best-effort)
    try:
        if query.message:
            await query.message.delete()
    except TelegramBadRequest:
        pass
    except Exception:
        pass

    data = (query.data or "").strip()
    if not data.startswith("pdfc:"):
        return

    parts = data.split(":")
    if len(parts) != 3:
        return

    action = parts[1]
    request_id = parts[2]
    user_id = query.from_user.id if query.from_user else 0

    log = logging.getLogger("pdf_cleaner.bot.handlers")
    adapter = logging.LoggerAdapter(log, {"request_id": request_id})

    rd = storage.request_dir(user_id, request_id)
    input_original = rd / "input_original.pdf"
    input_trimmed = rd / "input_trimmed.pdf"
    cleaned = rd / "cleaned.pdf"
    cleaned_small = rd / "cleaned_small.pdf"

    meta = storage.read_meta(user_id, request_id) or {}
    original_filename = meta.get("original_filename") or "document.pdf"

    if action == "pages":
        if not input_original.exists():
            await query.bot.send_message(user_id, "–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—Ç–ø—Ä–∞–≤—å—Ç–µ PDF –∑–∞–Ω–æ–≤–æ.")
            return

        _PENDING_PAGES_INPUT[user_id] = request_id
        meta["status"] = "awaiting_pages_input"
        meta["updated_at"] = int(time.time())
        storage.write_meta(user_id, request_id, meta)

        await query.bot.send_message(
            chat_id=query.message.chat.id if query.message else user_id,
            text=(
                "–í–≤–µ–¥–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
                "1, 2, 4-6\n\n"
                "–ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã: 1 2 4 5 6\n\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ 0 ‚Äî —á—Ç–æ–±—ã –æ—á–∏—Å—Ç–∏—Ç—å —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª–µ–Ω–∏—è."
            ),
        )
        return

    if action != "proc":
        return

    if not input_original.exists():
        await query.bot.send_message(
            chat_id=query.message.chat.id if query.message else user_id,
            text="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ PDF –∑–∞–Ω–æ–≤–æ.",
        )
        return

    # –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: trimmed –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ original
    source_pdf = input_trimmed if input_trimmed.exists() else input_original

    # –∫–≤–æ—Ç–∞: –µ—Å–ª–∏ —É–∂–µ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–æ ‚Äî –æ—Ç–∫–∞–∑—ã–≤–∞–µ–º
    if storage.would_exceed_quota(0):
        await query.bot.send_message(
            chat_id=query.message.chat.id if query.message else user_id,
            text="–•—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ (–ª–∏–º–∏—Ç 30 –ì–ë). –£–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
        )
        return

    status = str(meta.get("status") or "")
    if status == "processing":
        await query.bot.send_message(
            chat_id=query.message.chat.id if query.message else user_id,
            text="–§–∞–π–ª —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ.",
        )
        return

    try:
        async with process_lock:
            meta = storage.read_meta(user_id, request_id) or meta
            meta["status"] = "processing"
            meta["updated_at"] = int(time.time())
            storage.write_meta(user_id, request_id, meta)

            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ (source_pdf –Ω–µ –º—É—Ç–∏—Ä—É–µ–º)
            await asyncio.to_thread(
                processor.process_pdf,
                pdf_path=source_pdf,
                output_path=cleaned,
            )

            # shrink
            await asyncio.to_thread(shrink_pdf, cleaned, cleaned_small)

            # –∫–≤–æ—Ç–∞ –ø–æ—Å–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: rollback —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            if storage.would_exceed_quota(0):
                shutil.rmtree(rd, ignore_errors=True)
                await query.bot.send_message(
                    chat_id=query.message.chat.id if query.message else user_id,
                    text="–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø—Ä–µ–≤—ã—Å–∏–ª–æ –ª–∏–º–∏—Ç 30 –ì–ë. –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –£–¥–∞–ª–∏—Ç–µ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –≤ –≤–µ–±–∫–µ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.",
                )
                return

            meta["status"] = "done"
            meta["updated_at"] = int(time.time())
            meta["output"] = {
                "cleaned": {
                    "path": str(cleaned.relative_to(storage.cfg.root_dir)),
                    "size_bytes": cleaned.stat().st_size if cleaned.exists() else 0,
                },
                "cleaned_small": {
                    "path": str(cleaned_small.relative_to(storage.cfg.root_dir)),
                    "size_bytes": cleaned_small.stat().st_size if cleaned_small.exists() else 0,
                },
            }
            storage.write_meta(user_id, request_id, meta)

    except Exception as e:
        adapter.exception("Processing failed: %s", e)
        meta = storage.read_meta(user_id, request_id) or meta
        meta["status"] = "failed_processing"
        meta["updated_at"] = int(time.time())
        meta.setdefault("errors", []).append({"stage": "processing", "error": str(e)})
        storage.write_meta(user_id, request_id, meta)
        await query.bot.send_message(
            chat_id=query.message.chat.id if query.message else user_id,
            text="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥ —Å–µ—Ä–≤–µ—Ä–∞.",
        )
        return

    # –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ Telegram, —Å –¥—Ä–æ–±–ª–µ–Ω–∏–µ–º –µ—Å–ª–∏ > –ª–∏–º–∏—Ç–∞
    if not cleaned_small.exists():
        await query.bot.send_message(
            chat_id=query.message.chat.id if query.message else user_id,
            text="–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥ —Å–µ—Ä–≤–µ—Ä–∞.",
        )
        return

    result_size = cleaned_small.stat().st_size
    adapter.info("Result size=%s bytes", result_size)

    chat_id = query.message.chat.id if query.message else user_id
    stem = Path(original_filename).stem

    if result_size <= telegram_max_file_size:
        await query.bot.send_document(
            chat_id=chat_id,
            document=FSInputFile(path=str(cleaned_small), filename=original_filename),
            caption="–ì–æ—Ç–æ–≤–æ! –í–æ—Ç –≤–∞—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π PDF.",
        )
        return

    tmp_dir = Path("/tmp") / f"pdf_send_parts_{request_id}"
    try:
        parts_paths = _split_pdf_to_parts_under_limit(
            cleaned_small,
            max_bytes=telegram_max_file_size,
            tmp_root=tmp_dir,
            base_filename_stem=f"{stem}_cleaned",
            logger=adapter,
        )
    except Exception as e:
        adapter.exception("Split failed: %s", e)
        await query.bot.send_message(
            chat_id=chat_id,
            text=(
                "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π PDF –ø–æ–ª—É—á–∏–ª—Å—è –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞ Telegram –∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –µ–≥–æ —Ä–∞–∑–¥—Ä–æ–±–∏—Ç—å.\n\n"
                "–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ ‚Äî —Å–∫–∞—á–∞–π—Ç–µ –µ–≥–æ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å."
            ),
        )
        return

    total_parts = len(parts_paths)
    for idx, p in enumerate(parts_paths, start=1):
        cap = f"–ì–æ—Ç–æ–≤–æ! –ß–∞—Å—Ç—å {idx}/{total_parts}." if idx == 1 else f"–ß–∞—Å—Ç—å {idx}/{total_parts}."
        await query.bot.send_document(
            chat_id=chat_id,
            document=FSInputFile(path=str(p), filename=p.name),
            caption=cap,
        )

    shutil.rmtree(tmp_dir, ignore_errors=True)
